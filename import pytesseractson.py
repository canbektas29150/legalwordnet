# -*- coding: utf-8 -*-
import re
import unicodedata
import pandas as pd

# =========================
# 0) KullanÄ±cÄ±dan giriÅŸ/Ã§Ä±kÄ±ÅŸ isimlerini al
# =========================

INPUT_TXT = input("Girdi TXT dosyasÄ±nÄ±n adÄ± (Ã¶rn: cikti_u.txt): ").strip()
if not INPUT_TXT:
    print("âŒ Girdi dosya adÄ± boÅŸ olamaz!")
    raise SystemExit

if not INPUT_TXT.lower().endswith(".txt"):
    INPUT_TXT += ".txt"

OUTPUT_XLSX = input("Ã‡Ä±ktÄ± Excel dosyasÄ±nÄ±n adÄ± (Ã¶rn: sozluk_u.xlsx): ").strip()
if not OUTPUT_XLSX:
    print("âŒ Ã‡Ä±ktÄ± dosya adÄ± boÅŸ olamaz!")
    raise SystemExit

if not OUTPUT_XLSX.lower().endswith(".xlsx"):
    OUTPUT_XLSX += ".xlsx"

print(f"\nğŸ“¥ Girdi TXT: {INPUT_TXT}")
print(f"ğŸ“¤ Ã‡Ä±ktÄ± XLSX: {OUTPUT_XLSX}")

# =========================
# 1) Metni oku
# =========================
with open(INPUT_TXT, "r", encoding="utf-8") as f:
    raw = f.read()

# =========================
# 2) Normalizasyon ve temel temizlik
# =========================
text = unicodedata.normalize("NFC", raw)
text = re.sub(r"(?m)^\s*---\s*Sayfa\s*\d+\s*---\s*$", "", text)   # Sayfa baÅŸlÄ±klarÄ±nÄ± sil
text = text.replace("\u00ad", "")                                  # Soft hyphen temizle
text = re.sub(r"(\w)-\n(\w)", r"\1\2", text, flags=re.UNICODE)     # 'za-\nyÄ±f' -> 'zayÄ±f'

# Madde baÅŸlarÄ±nÄ± koru
PLACEHOLDER = "<<<ENTRYSEP>>>"
text = re.sub(r"\n\s*(?=[^\nâ€”]+?\sâ€”)", PLACEHOLDER, text)
text = re.sub(r"\n+", " ", text)
text = text.replace(PLACEHOLDER, "\n")
text = re.sub(r"\s{2,}", " ", text).strip()

# =========================
# 3) "kelime â€” anlam" bloklarÄ±nÄ± yakala
# =========================
pattern = re.compile(
    r"(?m)^\s*([^\nâ€”]+?)\sâ€”\s(.*?)(?=^\s*[^\nâ€”]+?\sâ€”\s|\Z)",
    flags=re.DOTALL
)

rows = []
for m in pattern.finditer(text):
    term = re.sub(r"\s{2,}", " ", m.group(1).strip())
    definition = re.sub(r"\s{2,}", " ", m.group(2).strip())
    definition = re.sub(r"\s+([,.;:!?])", r"\1", definition)
    if term and definition:
        rows.append({"kelime": term, "anlam": definition})

df = pd.DataFrame(rows, columns=["kelime", "anlam"])
print(f"\nğŸ“Š Toplam madde sayÄ±sÄ± (ham): {len(df)}")

# =========================
# 4) TÃ¼rkÃ§e alfabe ve sÄ±ralama yardÄ±mcÄ±larÄ±
# =========================

# TÃ¼rkÃ§e bÃ¼yÃ¼k harfe Ã§evirme (ÅŸapkalÄ±lar dÃ¢hil)
TR_UP_MAP = str.maketrans({
    "i": "Ä°", "Ä±": "I",
    "ÅŸ": "Å", "ÄŸ": "Ä", "Ã§": "Ã‡", "Ã¶": "Ã–", "Ã¼": "Ãœ",
    "Ã¢": "Ã‚", "Ã®": "Ã", "Ã»": "Ã›"
})
def tr_upper(s: str) -> str:
    return s.translate(TR_UP_MAP).upper()

# TÃ¼rkÃ§e alfabe (Q, W, X yok)
TR_ALPHABET = list("A B C Ã‡ D E F G Ä H I Ä° J K L M N O Ã– P R S Å T U Ãœ V Y Z".split())
ALPHA_INDEX = {ch: idx for idx, ch in enumerate(TR_ALPHABET)}

def tr_sort_key(word: str):
    """TÃ¼rkÃ§e harf sÄ±rasÄ±na gÃ¶re sÄ±ralama anahtarÄ±."""
    w = tr_upper(word)
    key = [ALPHA_INDEX.get(ch, 100 + ord(ch)) for ch in w]
    return key

def first_letter_bucket(term: str) -> str:
    """
    Kelimenin ilk harfine gÃ¶re doÄŸru sayfayÄ±/harfi belirle (Ã‚â†’A, Ãâ†’Ä°, Ã›â†’U).
    BaÅŸtaki tÄ±rnak, rakam, parantez vb. Ã§Ã¶pleri atmaya Ã§alÄ±ÅŸÄ±r.
    """
    if not term:
        return "#"
    t = term.strip()
    # BaÅŸtaki alakasÄ±z karakterleri temizle
    t = re.sub(r"^[^A-Za-zÃ‡ÄÄ°IÃ–ÅÃœÃ‚ÃÃ›Ã§ÄŸÄ±iÃ¶ÅŸÃ¼Ã¢Ã®Ã»]+", "", t)
    if not t:
        return "#"

    first = t[0]
    # ÅapkalÄ± yÃ¶nlendirme
    if first in ("Ã‚", "Ã¢"):
        return "A"
    elif first in ("Ã", "Ã®"):
        return "Ä°"
    elif first in ("Ã›", "Ã»"):
        return "U"

    first_up = tr_upper(first)
    return first_up if first_up in ALPHA_INDEX else "#"

# =========================
# 5) KullanÄ±cÄ±dan hangi harf iÃ§in sÃ¶zlÃ¼k yapÄ±lacaÄŸÄ±nÄ± al
# =========================
chosen = input("\nHangi harf iÃ§in sÃ¶zlÃ¼k oluÅŸturulsun? (Ã¶rn: U): ").strip()
if not chosen:
    print("âŒ Harf boÅŸ olamaz!")
    raise SystemExit

# KullanÄ±cÄ±nÄ±n girdiÄŸi harfi bucketa Ã§evir (Ã‚â†’A, Ã»â†’U gibi)
bucket = first_letter_bucket(chosen)
if bucket == "#":
    print(f"âŒ '{chosen}' iÃ§in geÃ§erli bir harf bulunamadÄ±.")
    raise SystemExit

print(f"ğŸ”  SeÃ§ilen harf: {chosen} â†’ gerÃ§ek bucket: {bucket}")

# =========================
# 6) Sadece bu harfle baÅŸlayan kelimeleri filtrele
# =========================
filtered_rows = []
for _, row in df.iterrows():
    b = first_letter_bucket(row["kelime"])
    if b == bucket:
        filtered_rows.append(row)

if not filtered_rows:
    print(f"âš ï¸ '{bucket}' harfiyle baÅŸlayan hiÃ§ madde bulunamadÄ±.")
    raise SystemExit

gdf = pd.DataFrame(filtered_rows, columns=["kelime", "anlam"])
print(f"âœ… '{bucket}' harfiyle baÅŸlayan madde sayÄ±sÄ±: {len(gdf)}")

# TÃ¼rkÃ§e sÄ±ralamaya gÃ¶re sÄ±rala
gdf = gdf.sort_values(by="kelime", key=lambda s: s.map(tr_sort_key), kind="stable")

# =========================
# 7) Excel'e yaz (sadece seÃ§ilen harf iÃ§in tek sheet)
# =========================
sheet_name = bucket  # Ã¶rn: "U"
if sheet_name == "#":
    sheet_name = "Diger"

with pd.ExcelWriter(OUTPUT_XLSX, engine="xlsxwriter") as writer:
    # Ä°steÄŸe baÄŸlÄ±: kÃ¼Ã§Ã¼k bir Ã¶zet sheet'i
    summary_df = pd.DataFrame(
        [{"Harf": bucket, "KayÄ±t SayÄ±sÄ±": len(gdf)}],
        columns=["Harf", "KayÄ±t SayÄ±sÄ±"]
    )
    summary_df.to_excel(writer, sheet_name="Ã–zet", index=False)
    ws_sum = writer.sheets["Ã–zet"]
    ws_sum.freeze_panes(1, 0)
    ws_sum.set_column(0, 0, 8)
    ws_sum.set_column(1, 1, 14)

    # AsÄ±l harf sheet'i
    gdf.to_excel(writer, sheet_name=sheet_name, index=False)
    ws = writer.sheets[sheet_name]
    ws.freeze_panes(1, 0)
    ws.set_column(0, 0, 28)  # kelime
    ws.set_column(1, 1, 90)  # anlam

print(f"\nâœ… '{bucket}' harfi iÃ§in TÃ¼rkÃ§e sÃ¶zlÃ¼k Excel dosyasÄ± oluÅŸturuldu â†’ {OUTPUT_XLSX}")
